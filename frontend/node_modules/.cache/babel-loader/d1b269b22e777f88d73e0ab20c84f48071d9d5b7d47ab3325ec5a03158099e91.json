{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.GridFSBucketWriteStream = void 0;\nconst stream_1 = require(\"stream\");\nconst bson_1 = require(\"../bson\");\nconst error_1 = require(\"../error\");\nconst write_concern_1 = require(\"./../write_concern\");\n/**\r\n * A writable stream that enables you to write buffers to GridFS.\r\n *\r\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\r\n * @public\r\n */\nclass GridFSBucketWriteStream extends stream_1.Writable {\n  /**\r\n   * @param bucket - Handle for this stream's corresponding bucket\r\n   * @param filename - The value of the 'filename' key in the files doc\r\n   * @param options - Optional settings.\r\n   * @internal\r\n   */\n  constructor(bucket, filename, options) {\n    super();\n    options = options ?? {};\n    this.bucket = bucket;\n    this.chunks = bucket.s._chunksCollection;\n    this.filename = filename;\n    this.files = bucket.s._filesCollection;\n    this.options = options;\n    this.writeConcern = write_concern_1.WriteConcern.fromOptions(options) || bucket.s.options.writeConcern;\n    // Signals the write is all done\n    this.done = false;\n    this.id = options.id ? options.id : new bson_1.ObjectId();\n    // properly inherit the default chunksize from parent\n    this.chunkSizeBytes = options.chunkSizeBytes || this.bucket.s.options.chunkSizeBytes;\n    this.bufToStore = Buffer.alloc(this.chunkSizeBytes);\n    this.length = 0;\n    this.n = 0;\n    this.pos = 0;\n    this.state = {\n      streamEnd: false,\n      outstandingRequests: 0,\n      errored: false,\n      aborted: false\n    };\n    if (!this.bucket.s.calledOpenUploadStream) {\n      this.bucket.s.calledOpenUploadStream = true;\n      checkIndexes(this).then(() => {\n        this.bucket.s.checkedIndexes = true;\n        this.bucket.emit('index');\n      }, () => null);\n    }\n  }\n  write(chunk, encodingOrCallback, callback) {\n    const encoding = typeof encodingOrCallback === 'function' ? undefined : encodingOrCallback;\n    callback = typeof encodingOrCallback === 'function' ? encodingOrCallback : callback;\n    return waitForIndexes(this, () => doWrite(this, chunk, encoding, callback));\n  }\n  /**\r\n   * Places this write stream into an aborted state (all future writes fail)\r\n   * and deletes all chunks that have already been written.\r\n   */\n  async abort() {\n    if (this.state.streamEnd) {\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n      throw new error_1.MongoAPIError('Cannot abort a stream that has already completed');\n    }\n    if (this.state.aborted) {\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n      throw new error_1.MongoAPIError('Cannot call abort() on a stream twice');\n    }\n    this.state.aborted = true;\n    await this.chunks.deleteMany({\n      files_id: this.id\n    });\n  }\n  end(chunkOrCallback, encodingOrCallback, callback) {\n    const chunk = typeof chunkOrCallback === 'function' ? undefined : chunkOrCallback;\n    const encoding = typeof encodingOrCallback === 'function' ? undefined : encodingOrCallback;\n    callback = typeof chunkOrCallback === 'function' ? chunkOrCallback : typeof encodingOrCallback === 'function' ? encodingOrCallback : callback;\n    if (this.state.streamEnd || checkAborted(this, callback)) return this;\n    this.state.streamEnd = true;\n    if (callback) {\n      this.once(GridFSBucketWriteStream.FINISH, result => {\n        if (callback) callback(undefined, result);\n      });\n    }\n    if (!chunk) {\n      waitForIndexes(this, () => !!writeRemnant(this));\n      return this;\n    }\n    this.write(chunk, encoding, () => {\n      writeRemnant(this);\n    });\n    return this;\n  }\n}\n/** @event */\nGridFSBucketWriteStream.CLOSE = 'close';\n/** @event */\nGridFSBucketWriteStream.ERROR = 'error';\n/**\r\n * `end()` was called and the write stream successfully wrote the file metadata and all the chunks to MongoDB.\r\n * @event\r\n */\nGridFSBucketWriteStream.FINISH = 'finish';\nexports.GridFSBucketWriteStream = GridFSBucketWriteStream;\nfunction __handleError(stream, error, callback) {\n  if (stream.state.errored) {\n    return;\n  }\n  stream.state.errored = true;\n  if (callback) {\n    return callback(error);\n  }\n  stream.emit(GridFSBucketWriteStream.ERROR, error);\n}\nfunction createChunkDoc(filesId, n, data) {\n  return {\n    _id: new bson_1.ObjectId(),\n    files_id: filesId,\n    n,\n    data\n  };\n}\nasync function checkChunksIndex(stream) {\n  const index = {\n    files_id: 1,\n    n: 1\n  };\n  let indexes;\n  try {\n    indexes = await stream.chunks.listIndexes().toArray();\n  } catch (error) {\n    if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n      indexes = [];\n    } else {\n      throw error;\n    }\n  }\n  const hasChunksIndex = !!indexes.find(index => {\n    const keys = Object.keys(index.key);\n    if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n      return true;\n    }\n    return false;\n  });\n  if (!hasChunksIndex) {\n    await stream.chunks.createIndex(index, {\n      ...stream.writeConcern,\n      background: true,\n      unique: true\n    });\n  }\n}\nfunction checkDone(stream, callback) {\n  if (stream.done) return true;\n  if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {\n    // Set done so we do not trigger duplicate createFilesDoc\n    stream.done = true;\n    // Create a new files doc\n    const filesDoc = createFilesDoc(stream.id, stream.length, stream.chunkSizeBytes, stream.filename, stream.options.contentType, stream.options.aliases, stream.options.metadata);\n    if (checkAborted(stream, callback)) {\n      return false;\n    }\n    stream.files.insertOne(filesDoc, {\n      writeConcern: stream.writeConcern\n    }).then(() => {\n      stream.emit(GridFSBucketWriteStream.FINISH, filesDoc);\n      stream.emit(GridFSBucketWriteStream.CLOSE);\n    }, error => {\n      return __handleError(stream, error, callback);\n    });\n    return true;\n  }\n  return false;\n}\nasync function checkIndexes(stream) {\n  const doc = await stream.files.findOne({}, {\n    projection: {\n      _id: 1\n    }\n  });\n  if (doc != null) {\n    // If at least one document exists assume the collection has the required index\n    return;\n  }\n  const index = {\n    filename: 1,\n    uploadDate: 1\n  };\n  let indexes;\n  try {\n    indexes = await stream.files.listIndexes().toArray();\n  } catch (error) {\n    if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n      indexes = [];\n    } else {\n      throw error;\n    }\n  }\n  const hasFileIndex = !!indexes.find(index => {\n    const keys = Object.keys(index.key);\n    if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n      return true;\n    }\n    return false;\n  });\n  if (!hasFileIndex) {\n    await stream.files.createIndex(index, {\n      background: false\n    });\n  }\n  await checkChunksIndex(stream);\n}\nfunction createFilesDoc(_id, length, chunkSize, filename, contentType, aliases, metadata) {\n  const ret = {\n    _id,\n    length,\n    chunkSize,\n    uploadDate: new Date(),\n    filename\n  };\n  if (contentType) {\n    ret.contentType = contentType;\n  }\n  if (aliases) {\n    ret.aliases = aliases;\n  }\n  if (metadata) {\n    ret.metadata = metadata;\n  }\n  return ret;\n}\nfunction doWrite(stream, chunk, encoding, callback) {\n  if (checkAborted(stream, callback)) {\n    return false;\n  }\n  const inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\n  stream.length += inputBuf.length;\n  // Input is small enough to fit in our buffer\n  if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {\n    inputBuf.copy(stream.bufToStore, stream.pos);\n    stream.pos += inputBuf.length;\n    callback && callback();\n    // Note that we reverse the typical semantics of write's return value\n    // to be compatible with node's `.pipe()` function.\n    // True means client can keep writing.\n    return true;\n  }\n  // Otherwise, buffer is too big for current chunk, so we need to flush\n  // to MongoDB.\n  let inputBufRemaining = inputBuf.length;\n  let spaceRemaining = stream.chunkSizeBytes - stream.pos;\n  let numToCopy = Math.min(spaceRemaining, inputBuf.length);\n  let outstandingRequests = 0;\n  while (inputBufRemaining > 0) {\n    const inputBufPos = inputBuf.length - inputBufRemaining;\n    inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);\n    stream.pos += numToCopy;\n    spaceRemaining -= numToCopy;\n    let doc;\n    if (spaceRemaining === 0) {\n      doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));\n      ++stream.state.outstandingRequests;\n      ++outstandingRequests;\n      if (checkAborted(stream, callback)) {\n        return false;\n      }\n      stream.chunks.insertOne(doc, {\n        writeConcern: stream.writeConcern\n      }).then(() => {\n        --stream.state.outstandingRequests;\n        --outstandingRequests;\n        if (!outstandingRequests) {\n          stream.emit('drain', doc);\n          callback && callback();\n          checkDone(stream);\n        }\n      }, error => {\n        return __handleError(stream, error);\n      });\n      spaceRemaining = stream.chunkSizeBytes;\n      stream.pos = 0;\n      ++stream.n;\n    }\n    inputBufRemaining -= numToCopy;\n    numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n  }\n  // Note that we reverse the typical semantics of write's return value\n  // to be compatible with node's `.pipe()` function.\n  // False means the client should wait for the 'drain' event.\n  return false;\n}\nfunction waitForIndexes(stream, callback) {\n  if (stream.bucket.s.checkedIndexes) {\n    return callback(false);\n  }\n  stream.bucket.once('index', () => {\n    callback(true);\n  });\n  return true;\n}\nfunction writeRemnant(stream, callback) {\n  // Buffer is empty, so don't bother to insert\n  if (stream.pos === 0) {\n    return checkDone(stream, callback);\n  }\n  ++stream.state.outstandingRequests;\n  // Create a new buffer to make sure the buffer isn't bigger than it needs\n  // to be.\n  const remnant = Buffer.alloc(stream.pos);\n  stream.bufToStore.copy(remnant, 0, 0, stream.pos);\n  const doc = createChunkDoc(stream.id, stream.n, remnant);\n  // If the stream was aborted, do not write remnant\n  if (checkAborted(stream, callback)) {\n    return false;\n  }\n  stream.chunks.insertOne(doc, {\n    writeConcern: stream.writeConcern\n  }).then(() => {\n    --stream.state.outstandingRequests;\n    checkDone(stream);\n  }, error => {\n    return __handleError(stream, error);\n  });\n  return true;\n}\nfunction checkAborted(stream, callback) {\n  if (stream.state.aborted) {\n    if (typeof callback === 'function') {\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosedError\n      callback(new error_1.MongoAPIError('Stream has been aborted'));\n    }\n    return true;\n  }\n  return false;\n}","map":{"version":3,"mappings":";;;;;;AAAA;AAGA;AAEA;AAGA;AA0BA;;;;;;AAMA,MAAaA,uBAAwB,SAAQC,iBAAQ;EA+BnD;;;;;;EAMAC,YAAYC,MAAoB,EAAEC,QAAgB,EAAEC,OAAwC;IAC1F,KAAK,EAAE;IAEPA,OAAO,GAAGA,OAAO,IAAI,EAAE;IACvB,IAAI,CAACF,MAAM,GAAGA,MAAM;IACpB,IAAI,CAACG,MAAM,GAAGH,MAAM,CAACI,CAAC,CAACC,iBAAiB;IACxC,IAAI,CAACJ,QAAQ,GAAGA,QAAQ;IACxB,IAAI,CAACK,KAAK,GAAGN,MAAM,CAACI,CAAC,CAACG,gBAAgB;IACtC,IAAI,CAACL,OAAO,GAAGA,OAAO;IACtB,IAAI,CAACM,YAAY,GAAGC,4BAAY,CAACC,WAAW,CAACR,OAAO,CAAC,IAAIF,MAAM,CAACI,CAAC,CAACF,OAAO,CAACM,YAAY;IACtF;IACA,IAAI,CAACG,IAAI,GAAG,KAAK;IAEjB,IAAI,CAACC,EAAE,GAAGV,OAAO,CAACU,EAAE,GAAGV,OAAO,CAACU,EAAE,GAAG,IAAIC,eAAQ,EAAE;IAClD;IACA,IAAI,CAACC,cAAc,GAAGZ,OAAO,CAACY,cAAc,IAAI,IAAI,CAACd,MAAM,CAACI,CAAC,CAACF,OAAO,CAACY,cAAc;IACpF,IAAI,CAACC,UAAU,GAAGC,MAAM,CAACC,KAAK,CAAC,IAAI,CAACH,cAAc,CAAC;IACnD,IAAI,CAACI,MAAM,GAAG,CAAC;IACf,IAAI,CAACC,CAAC,GAAG,CAAC;IACV,IAAI,CAACC,GAAG,GAAG,CAAC;IACZ,IAAI,CAACC,KAAK,GAAG;MACXC,SAAS,EAAE,KAAK;MAChBC,mBAAmB,EAAE,CAAC;MACtBC,OAAO,EAAE,KAAK;MACdC,OAAO,EAAE;KACV;IAED,IAAI,CAAC,IAAI,CAACzB,MAAM,CAACI,CAAC,CAACsB,sBAAsB,EAAE;MACzC,IAAI,CAAC1B,MAAM,CAACI,CAAC,CAACsB,sBAAsB,GAAG,IAAI;MAE3CC,YAAY,CAAC,IAAI,CAAC,CAACC,IAAI,CACrB,MAAK;QACH,IAAI,CAAC5B,MAAM,CAACI,CAAC,CAACyB,cAAc,GAAG,IAAI;QACnC,IAAI,CAAC7B,MAAM,CAAC8B,IAAI,CAAC,OAAO,CAAC;MAC3B,CAAC,EACD,MAAM,IAAI,CACX;;EAEL;EAkBSC,KAAK,CACZC,KAAsB,EACtBC,kBAAoD,EACpDC,QAAyB;IAEzB,MAAMC,QAAQ,GAAG,OAAOF,kBAAkB,KAAK,UAAU,GAAGG,SAAS,GAAGH,kBAAkB;IAC1FC,QAAQ,GAAG,OAAOD,kBAAkB,KAAK,UAAU,GAAGA,kBAAkB,GAAGC,QAAQ;IACnF,OAAOG,cAAc,CAAC,IAAI,EAAE,MAAMC,OAAO,CAAC,IAAI,EAAEN,KAAK,EAAEG,QAAQ,EAAED,QAAQ,CAAC,CAAC;EAC7E;EAEA;;;;EAIA,MAAMK,KAAK;IACT,IAAI,IAAI,CAAClB,KAAK,CAACC,SAAS,EAAE;MACxB;MACA,MAAM,IAAIkB,qBAAa,CAAC,kDAAkD,CAAC;;IAG7E,IAAI,IAAI,CAACnB,KAAK,CAACI,OAAO,EAAE;MACtB;MACA,MAAM,IAAIe,qBAAa,CAAC,uCAAuC,CAAC;;IAGlE,IAAI,CAACnB,KAAK,CAACI,OAAO,GAAG,IAAI;IACzB,MAAM,IAAI,CAACtB,MAAM,CAACsC,UAAU,CAAC;MAAEC,QAAQ,EAAE,IAAI,CAAC9B;IAAE,CAAE,CAAC;EACrD;EAqBS+B,GAAG,CACVC,eAAsD,EACtDX,kBAAiE,EACjEC,QAAsC;IAEtC,MAAMF,KAAK,GAAG,OAAOY,eAAe,KAAK,UAAU,GAAGR,SAAS,GAAGQ,eAAe;IACjF,MAAMT,QAAQ,GAAG,OAAOF,kBAAkB,KAAK,UAAU,GAAGG,SAAS,GAAGH,kBAAkB;IAC1FC,QAAQ,GACN,OAAOU,eAAe,KAAK,UAAU,GACjCA,eAAe,GACf,OAAOX,kBAAkB,KAAK,UAAU,GACxCA,kBAAkB,GAClBC,QAAQ;IAEd,IAAI,IAAI,CAACb,KAAK,CAACC,SAAS,IAAIuB,YAAY,CAAC,IAAI,EAAEX,QAAQ,CAAC,EAAE,OAAO,IAAI;IAErE,IAAI,CAACb,KAAK,CAACC,SAAS,GAAG,IAAI;IAE3B,IAAIY,QAAQ,EAAE;MACZ,IAAI,CAACY,IAAI,CAACjD,uBAAuB,CAACkD,MAAM,EAAGC,MAAkB,IAAI;QAC/D,IAAId,QAAQ,EAAEA,QAAQ,CAACE,SAAS,EAAEY,MAAM,CAAC;MAC3C,CAAC,CAAC;;IAGJ,IAAI,CAAChB,KAAK,EAAE;MACVK,cAAc,CAAC,IAAI,EAAE,MAAM,CAAC,CAACY,YAAY,CAAC,IAAI,CAAC,CAAC;MAChD,OAAO,IAAI;;IAGb,IAAI,CAAClB,KAAK,CAACC,KAAK,EAAEG,QAAQ,EAAE,MAAK;MAC/Bc,YAAY,CAAC,IAAI,CAAC;IACpB,CAAC,CAAC;IAEF,OAAO,IAAI;EACb;;AA1JA;AACgBpD,6BAAK,GAAG,OAAO;AAC/B;AACgBA,6BAAK,GAAG,OAAO;AAC/B;;;;AAIgBA,8BAAM,GAAG,QAAQ;AA7BtBqD;AAkLb,SAASC,aAAa,CACpBC,MAA+B,EAC/BC,KAAe,EACfnB,QAAmB;EAEnB,IAAIkB,MAAM,CAAC/B,KAAK,CAACG,OAAO,EAAE;IACxB;;EAEF4B,MAAM,CAAC/B,KAAK,CAACG,OAAO,GAAG,IAAI;EAC3B,IAAIU,QAAQ,EAAE;IACZ,OAAOA,QAAQ,CAACmB,KAAK,CAAC;;EAExBD,MAAM,CAACtB,IAAI,CAACjC,uBAAuB,CAACyD,KAAK,EAAED,KAAK,CAAC;AACnD;AAEA,SAASE,cAAc,CAACC,OAAiB,EAAErC,CAAS,EAAEsC,IAAY;EAChE,OAAO;IACLC,GAAG,EAAE,IAAI7C,eAAQ,EAAE;IACnB6B,QAAQ,EAAEc,OAAO;IACjBrC,CAAC;IACDsC;GACD;AACH;AAEA,eAAeE,gBAAgB,CAACP,MAA+B;EAC7D,MAAMQ,KAAK,GAAG;IAAElB,QAAQ,EAAE,CAAC;IAAEvB,CAAC,EAAE;EAAC,CAAE;EAEnC,IAAI0C,OAAO;EACX,IAAI;IACFA,OAAO,GAAG,MAAMT,MAAM,CAACjD,MAAM,CAAC2D,WAAW,EAAE,CAACC,OAAO,EAAE;GACtD,CAAC,OAAOV,KAAK,EAAE;IACd,IAAIA,KAAK,YAAYb,kBAAU,IAAIa,KAAK,CAACW,IAAI,KAAKxB,2BAAmB,CAACyB,iBAAiB,EAAE;MACvFJ,OAAO,GAAG,EAAE;KACb,MAAM;MACL,MAAMR,KAAK;;;EAIf,MAAMa,cAAc,GAAG,CAAC,CAACL,OAAO,CAACM,IAAI,CAACP,KAAK,IAAG;IAC5C,MAAMQ,IAAI,GAAGC,MAAM,CAACD,IAAI,CAACR,KAAK,CAACU,GAAG,CAAC;IACnC,IAAIF,IAAI,CAAClD,MAAM,KAAK,CAAC,IAAI0C,KAAK,CAACU,GAAG,CAAC5B,QAAQ,KAAK,CAAC,IAAIkB,KAAK,CAACU,GAAG,CAACnD,CAAC,KAAK,CAAC,EAAE;MACtE,OAAO,IAAI;;IAEb,OAAO,KAAK;EACd,CAAC,CAAC;EAEF,IAAI,CAAC+C,cAAc,EAAE;IACnB,MAAMd,MAAM,CAACjD,MAAM,CAACoE,WAAW,CAACX,KAAK,EAAE;MACrC,GAAGR,MAAM,CAAC5C,YAAY;MACtBgE,UAAU,EAAE,IAAI;MAChBC,MAAM,EAAE;KACT,CAAC;;AAEN;AAEA,SAASC,SAAS,CAACtB,MAA+B,EAAElB,QAAmB;EACrE,IAAIkB,MAAM,CAACzC,IAAI,EAAE,OAAO,IAAI;EAC5B,IAAIyC,MAAM,CAAC/B,KAAK,CAACC,SAAS,IAAI8B,MAAM,CAAC/B,KAAK,CAACE,mBAAmB,KAAK,CAAC,IAAI,CAAC6B,MAAM,CAAC/B,KAAK,CAACG,OAAO,EAAE;IAC7F;IACA4B,MAAM,CAACzC,IAAI,GAAG,IAAI;IAClB;IACA,MAAMgE,QAAQ,GAAGC,cAAc,CAC7BxB,MAAM,CAACxC,EAAE,EACTwC,MAAM,CAAClC,MAAM,EACbkC,MAAM,CAACtC,cAAc,EACrBsC,MAAM,CAACnD,QAAQ,EACfmD,MAAM,CAAClD,OAAO,CAAC2E,WAAW,EAC1BzB,MAAM,CAAClD,OAAO,CAAC4E,OAAO,EACtB1B,MAAM,CAAClD,OAAO,CAAC6E,QAAQ,CACxB;IAED,IAAIlC,YAAY,CAACO,MAAM,EAAElB,QAAQ,CAAC,EAAE;MAClC,OAAO,KAAK;;IAGdkB,MAAM,CAAC9C,KAAK,CAAC0E,SAAS,CAACL,QAAQ,EAAE;MAAEnE,YAAY,EAAE4C,MAAM,CAAC5C;IAAY,CAAE,CAAC,CAACoB,IAAI,CAC1E,MAAK;MACHwB,MAAM,CAACtB,IAAI,CAACjC,uBAAuB,CAACkD,MAAM,EAAE4B,QAAQ,CAAC;MACrDvB,MAAM,CAACtB,IAAI,CAACjC,uBAAuB,CAACoF,KAAK,CAAC;IAC5C,CAAC,EACD5B,KAAK,IAAG;MACN,OAAOF,aAAa,CAACC,MAAM,EAAEC,KAAK,EAAEnB,QAAQ,CAAC;IAC/C,CAAC,CACF;IAED,OAAO,IAAI;;EAGb,OAAO,KAAK;AACd;AAEA,eAAeP,YAAY,CAACyB,MAA+B;EACzD,MAAM8B,GAAG,GAAG,MAAM9B,MAAM,CAAC9C,KAAK,CAAC6E,OAAO,CAAC,EAAE,EAAE;IAAEC,UAAU,EAAE;MAAE1B,GAAG,EAAE;IAAC;EAAE,CAAE,CAAC;EACtE,IAAIwB,GAAG,IAAI,IAAI,EAAE;IACf;IACA;;EAGF,MAAMtB,KAAK,GAAG;IAAE3D,QAAQ,EAAE,CAAC;IAAEoF,UAAU,EAAE;EAAC,CAAE;EAE5C,IAAIxB,OAAO;EACX,IAAI;IACFA,OAAO,GAAG,MAAMT,MAAM,CAAC9C,KAAK,CAACwD,WAAW,EAAE,CAACC,OAAO,EAAE;GACrD,CAAC,OAAOV,KAAK,EAAE;IACd,IAAIA,KAAK,YAAYb,kBAAU,IAAIa,KAAK,CAACW,IAAI,KAAKxB,2BAAmB,CAACyB,iBAAiB,EAAE;MACvFJ,OAAO,GAAG,EAAE;KACb,MAAM;MACL,MAAMR,KAAK;;;EAIf,MAAMiC,YAAY,GAAG,CAAC,CAACzB,OAAO,CAACM,IAAI,CAACP,KAAK,IAAG;IAC1C,MAAMQ,IAAI,GAAGC,MAAM,CAACD,IAAI,CAACR,KAAK,CAACU,GAAG,CAAC;IACnC,IAAIF,IAAI,CAAClD,MAAM,KAAK,CAAC,IAAI0C,KAAK,CAACU,GAAG,CAACrE,QAAQ,KAAK,CAAC,IAAI2D,KAAK,CAACU,GAAG,CAACe,UAAU,KAAK,CAAC,EAAE;MAC/E,OAAO,IAAI;;IAEb,OAAO,KAAK;EACd,CAAC,CAAC;EAEF,IAAI,CAACC,YAAY,EAAE;IACjB,MAAMlC,MAAM,CAAC9C,KAAK,CAACiE,WAAW,CAACX,KAAK,EAAE;MAAEY,UAAU,EAAE;IAAK,CAAE,CAAC;;EAG9D,MAAMb,gBAAgB,CAACP,MAAM,CAAC;AAChC;AAEA,SAASwB,cAAc,CACrBlB,GAAa,EACbxC,MAAc,EACdqE,SAAiB,EACjBtF,QAAgB,EAChB4E,WAAoB,EACpBC,OAAkB,EAClBC,QAAmB;EAEnB,MAAMS,GAAG,GAAe;IACtB9B,GAAG;IACHxC,MAAM;IACNqE,SAAS;IACTF,UAAU,EAAE,IAAII,IAAI,EAAE;IACtBxF;GACD;EAED,IAAI4E,WAAW,EAAE;IACfW,GAAG,CAACX,WAAW,GAAGA,WAAW;;EAG/B,IAAIC,OAAO,EAAE;IACXU,GAAG,CAACV,OAAO,GAAGA,OAAO;;EAGvB,IAAIC,QAAQ,EAAE;IACZS,GAAG,CAACT,QAAQ,GAAGA,QAAQ;;EAGzB,OAAOS,GAAG;AACZ;AAEA,SAASlD,OAAO,CACdc,MAA+B,EAC/BpB,KAAsB,EACtBG,QAAyB,EACzBD,QAAyB;EAEzB,IAAIW,YAAY,CAACO,MAAM,EAAElB,QAAQ,CAAC,EAAE;IAClC,OAAO,KAAK;;EAGd,MAAMwD,QAAQ,GAAG1E,MAAM,CAAC2E,QAAQ,CAAC3D,KAAK,CAAC,GAAGA,KAAK,GAAGhB,MAAM,CAAC4E,IAAI,CAAC5D,KAAK,EAAEG,QAAQ,CAAC;EAE9EiB,MAAM,CAAClC,MAAM,IAAIwE,QAAQ,CAACxE,MAAM;EAEhC;EACA,IAAIkC,MAAM,CAAChC,GAAG,GAAGsE,QAAQ,CAACxE,MAAM,GAAGkC,MAAM,CAACtC,cAAc,EAAE;IACxD4E,QAAQ,CAACG,IAAI,CAACzC,MAAM,CAACrC,UAAU,EAAEqC,MAAM,CAAChC,GAAG,CAAC;IAC5CgC,MAAM,CAAChC,GAAG,IAAIsE,QAAQ,CAACxE,MAAM;IAE7BgB,QAAQ,IAAIA,QAAQ,EAAE;IAEtB;IACA;IACA;IACA,OAAO,IAAI;;EAGb;EACA;EACA,IAAI4D,iBAAiB,GAAGJ,QAAQ,CAACxE,MAAM;EACvC,IAAI6E,cAAc,GAAW3C,MAAM,CAACtC,cAAc,GAAGsC,MAAM,CAAChC,GAAG;EAC/D,IAAI4E,SAAS,GAAGC,IAAI,CAACC,GAAG,CAACH,cAAc,EAAEL,QAAQ,CAACxE,MAAM,CAAC;EACzD,IAAIK,mBAAmB,GAAG,CAAC;EAC3B,OAAOuE,iBAAiB,GAAG,CAAC,EAAE;IAC5B,MAAMK,WAAW,GAAGT,QAAQ,CAACxE,MAAM,GAAG4E,iBAAiB;IACvDJ,QAAQ,CAACG,IAAI,CAACzC,MAAM,CAACrC,UAAU,EAAEqC,MAAM,CAAChC,GAAG,EAAE+E,WAAW,EAAEA,WAAW,GAAGH,SAAS,CAAC;IAClF5C,MAAM,CAAChC,GAAG,IAAI4E,SAAS;IACvBD,cAAc,IAAIC,SAAS;IAC3B,IAAId,GAAgB;IACpB,IAAIa,cAAc,KAAK,CAAC,EAAE;MACxBb,GAAG,GAAG3B,cAAc,CAACH,MAAM,CAACxC,EAAE,EAAEwC,MAAM,CAACjC,CAAC,EAAEH,MAAM,CAAC4E,IAAI,CAACxC,MAAM,CAACrC,UAAU,CAAC,CAAC;MACzE,EAAEqC,MAAM,CAAC/B,KAAK,CAACE,mBAAmB;MAClC,EAAEA,mBAAmB;MAErB,IAAIsB,YAAY,CAACO,MAAM,EAAElB,QAAQ,CAAC,EAAE;QAClC,OAAO,KAAK;;MAGdkB,MAAM,CAACjD,MAAM,CAAC6E,SAAS,CAACE,GAAG,EAAE;QAAE1E,YAAY,EAAE4C,MAAM,CAAC5C;MAAY,CAAE,CAAC,CAACoB,IAAI,CACtE,MAAK;QACH,EAAEwB,MAAM,CAAC/B,KAAK,CAACE,mBAAmB;QAClC,EAAEA,mBAAmB;QAErB,IAAI,CAACA,mBAAmB,EAAE;UACxB6B,MAAM,CAACtB,IAAI,CAAC,OAAO,EAAEoD,GAAG,CAAC;UACzBhD,QAAQ,IAAIA,QAAQ,EAAE;UACtBwC,SAAS,CAACtB,MAAM,CAAC;;MAErB,CAAC,EACDC,KAAK,IAAG;QACN,OAAOF,aAAa,CAACC,MAAM,EAAEC,KAAK,CAAC;MACrC,CAAC,CACF;MAED0C,cAAc,GAAG3C,MAAM,CAACtC,cAAc;MACtCsC,MAAM,CAAChC,GAAG,GAAG,CAAC;MACd,EAAEgC,MAAM,CAACjC,CAAC;;IAEZ2E,iBAAiB,IAAIE,SAAS;IAC9BA,SAAS,GAAGC,IAAI,CAACC,GAAG,CAACH,cAAc,EAAED,iBAAiB,CAAC;;EAGzD;EACA;EACA;EACA,OAAO,KAAK;AACd;AAEA,SAASzD,cAAc,CACrBe,MAA+B,EAC/BlB,QAAmC;EAEnC,IAAIkB,MAAM,CAACpD,MAAM,CAACI,CAAC,CAACyB,cAAc,EAAE;IAClC,OAAOK,QAAQ,CAAC,KAAK,CAAC;;EAGxBkB,MAAM,CAACpD,MAAM,CAAC8C,IAAI,CAAC,OAAO,EAAE,MAAK;IAC/BZ,QAAQ,CAAC,IAAI,CAAC;EAChB,CAAC,CAAC;EAEF,OAAO,IAAI;AACb;AAEA,SAASe,YAAY,CAACG,MAA+B,EAAElB,QAAmB;EACxE;EACA,IAAIkB,MAAM,CAAChC,GAAG,KAAK,CAAC,EAAE;IACpB,OAAOsD,SAAS,CAACtB,MAAM,EAAElB,QAAQ,CAAC;;EAGpC,EAAEkB,MAAM,CAAC/B,KAAK,CAACE,mBAAmB;EAElC;EACA;EACA,MAAM6E,OAAO,GAAGpF,MAAM,CAACC,KAAK,CAACmC,MAAM,CAAChC,GAAG,CAAC;EACxCgC,MAAM,CAACrC,UAAU,CAAC8E,IAAI,CAACO,OAAO,EAAE,CAAC,EAAE,CAAC,EAAEhD,MAAM,CAAChC,GAAG,CAAC;EACjD,MAAM8D,GAAG,GAAG3B,cAAc,CAACH,MAAM,CAACxC,EAAE,EAAEwC,MAAM,CAACjC,CAAC,EAAEiF,OAAO,CAAC;EAExD;EACA,IAAIvD,YAAY,CAACO,MAAM,EAAElB,QAAQ,CAAC,EAAE;IAClC,OAAO,KAAK;;EAGdkB,MAAM,CAACjD,MAAM,CAAC6E,SAAS,CAACE,GAAG,EAAE;IAAE1E,YAAY,EAAE4C,MAAM,CAAC5C;EAAY,CAAE,CAAC,CAACoB,IAAI,CACtE,MAAK;IACH,EAAEwB,MAAM,CAAC/B,KAAK,CAACE,mBAAmB;IAClCmD,SAAS,CAACtB,MAAM,CAAC;EACnB,CAAC,EACDC,KAAK,IAAG;IACN,OAAOF,aAAa,CAACC,MAAM,EAAEC,KAAK,CAAC;EACrC,CAAC,CACF;EACD,OAAO,IAAI;AACb;AAEA,SAASR,YAAY,CAACO,MAA+B,EAAElB,QAAyB;EAC9E,IAAIkB,MAAM,CAAC/B,KAAK,CAACI,OAAO,EAAE;IACxB,IAAI,OAAOS,QAAQ,KAAK,UAAU,EAAE;MAClC;MACAA,QAAQ,CAAC,IAAIM,qBAAa,CAAC,yBAAyB,CAAC,CAAC;;IAExD,OAAO,IAAI;;EAEb,OAAO,KAAK;AACd","names":["GridFSBucketWriteStream","stream_1","constructor","bucket","filename","options","chunks","s","_chunksCollection","files","_filesCollection","writeConcern","write_concern_1","fromOptions","done","id","bson_1","chunkSizeBytes","bufToStore","Buffer","alloc","length","n","pos","state","streamEnd","outstandingRequests","errored","aborted","calledOpenUploadStream","checkIndexes","then","checkedIndexes","emit","write","chunk","encodingOrCallback","callback","encoding","undefined","waitForIndexes","doWrite","abort","error_1","deleteMany","files_id","end","chunkOrCallback","checkAborted","once","FINISH","result","writeRemnant","exports","__handleError","stream","error","ERROR","createChunkDoc","filesId","data","_id","checkChunksIndex","index","indexes","listIndexes","toArray","code","NamespaceNotFound","hasChunksIndex","find","keys","Object","key","createIndex","background","unique","checkDone","filesDoc","createFilesDoc","contentType","aliases","metadata","insertOne","CLOSE","doc","findOne","projection","uploadDate","hasFileIndex","chunkSize","ret","Date","inputBuf","isBuffer","from","copy","inputBufRemaining","spaceRemaining","numToCopy","Math","min","inputBufPos","remnant"],"sources":["C:\\Users\\joelg\\Downloads\\MernStack-Tour-Management-main\\MernStack-Tour-Management-main\\tour-management\\node_modules\\mongodb\\src\\gridfs\\upload.ts"],"sourcesContent":["import { Writable } from 'stream';\r\n\r\nimport type { Document } from '../bson';\r\nimport { ObjectId } from '../bson';\r\nimport type { Collection } from '../collection';\r\nimport { type AnyError, MongoAPIError, MONGODB_ERROR_CODES, MongoError } from '../error';\r\nimport type { Callback } from '../utils';\r\nimport type { WriteConcernOptions } from '../write_concern';\r\nimport { WriteConcern } from './../write_concern';\r\nimport type { GridFSFile } from './download';\r\nimport type { GridFSBucket } from './index';\r\n\r\n/** @public */\r\nexport interface GridFSChunk {\r\n  _id: ObjectId;\r\n  files_id: ObjectId;\r\n  n: number;\r\n  data: Buffer | Uint8Array;\r\n}\r\n\r\n/** @public */\r\nexport interface GridFSBucketWriteStreamOptions extends WriteConcernOptions {\r\n  /** Overwrite this bucket's chunkSizeBytes for this file */\r\n  chunkSizeBytes?: number;\r\n  /** Custom file id for the GridFS file. */\r\n  id?: ObjectId;\r\n  /** Object to store in the file document's `metadata` field */\r\n  metadata?: Document;\r\n  /** String to store in the file document's `contentType` field */\r\n  contentType?: string;\r\n  /** Array of strings to store in the file document's `aliases` field */\r\n  aliases?: string[];\r\n}\r\n\r\n/**\r\n * A writable stream that enables you to write buffers to GridFS.\r\n *\r\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\r\n * @public\r\n */\r\nexport class GridFSBucketWriteStream extends Writable implements NodeJS.WritableStream {\r\n  bucket: GridFSBucket;\r\n  chunks: Collection<GridFSChunk>;\r\n  filename: string;\r\n  files: Collection<GridFSFile>;\r\n  options: GridFSBucketWriteStreamOptions;\r\n  done: boolean;\r\n  id: ObjectId;\r\n  chunkSizeBytes: number;\r\n  bufToStore: Buffer;\r\n  length: number;\r\n  n: number;\r\n  pos: number;\r\n  state: {\r\n    streamEnd: boolean;\r\n    outstandingRequests: number;\r\n    errored: boolean;\r\n    aborted: boolean;\r\n  };\r\n  writeConcern?: WriteConcern;\r\n\r\n  /** @event */\r\n  static readonly CLOSE = 'close';\r\n  /** @event */\r\n  static readonly ERROR = 'error';\r\n  /**\r\n   * `end()` was called and the write stream successfully wrote the file metadata and all the chunks to MongoDB.\r\n   * @event\r\n   */\r\n  static readonly FINISH = 'finish';\r\n\r\n  /**\r\n   * @param bucket - Handle for this stream's corresponding bucket\r\n   * @param filename - The value of the 'filename' key in the files doc\r\n   * @param options - Optional settings.\r\n   * @internal\r\n   */\r\n  constructor(bucket: GridFSBucket, filename: string, options?: GridFSBucketWriteStreamOptions) {\r\n    super();\r\n\r\n    options = options ?? {};\r\n    this.bucket = bucket;\r\n    this.chunks = bucket.s._chunksCollection;\r\n    this.filename = filename;\r\n    this.files = bucket.s._filesCollection;\r\n    this.options = options;\r\n    this.writeConcern = WriteConcern.fromOptions(options) || bucket.s.options.writeConcern;\r\n    // Signals the write is all done\r\n    this.done = false;\r\n\r\n    this.id = options.id ? options.id : new ObjectId();\r\n    // properly inherit the default chunksize from parent\r\n    this.chunkSizeBytes = options.chunkSizeBytes || this.bucket.s.options.chunkSizeBytes;\r\n    this.bufToStore = Buffer.alloc(this.chunkSizeBytes);\r\n    this.length = 0;\r\n    this.n = 0;\r\n    this.pos = 0;\r\n    this.state = {\r\n      streamEnd: false,\r\n      outstandingRequests: 0,\r\n      errored: false,\r\n      aborted: false\r\n    };\r\n\r\n    if (!this.bucket.s.calledOpenUploadStream) {\r\n      this.bucket.s.calledOpenUploadStream = true;\r\n\r\n      checkIndexes(this).then(\r\n        () => {\r\n          this.bucket.s.checkedIndexes = true;\r\n          this.bucket.emit('index');\r\n        },\r\n        () => null\r\n      );\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Write a buffer to the stream.\r\n   *\r\n   * @param chunk - Buffer to write\r\n   * @param encodingOrCallback - Optional encoding for the buffer\r\n   * @param callback - Function to call when the chunk was added to the buffer, or if the entire chunk was persisted to MongoDB if this chunk caused a flush.\r\n   * @returns False if this write required flushing a chunk to MongoDB. True otherwise.\r\n   */\r\n  override write(chunk: Buffer | string): boolean;\r\n  override write(chunk: Buffer | string, callback: Callback<void>): boolean;\r\n  override write(chunk: Buffer | string, encoding: BufferEncoding | undefined): boolean;\r\n  override write(\r\n    chunk: Buffer | string,\r\n    encoding: BufferEncoding | undefined,\r\n    callback: Callback<void>\r\n  ): boolean;\r\n  override write(\r\n    chunk: Buffer | string,\r\n    encodingOrCallback?: Callback<void> | BufferEncoding,\r\n    callback?: Callback<void>\r\n  ): boolean {\r\n    const encoding = typeof encodingOrCallback === 'function' ? undefined : encodingOrCallback;\r\n    callback = typeof encodingOrCallback === 'function' ? encodingOrCallback : callback;\r\n    return waitForIndexes(this, () => doWrite(this, chunk, encoding, callback));\r\n  }\r\n\r\n  /**\r\n   * Places this write stream into an aborted state (all future writes fail)\r\n   * and deletes all chunks that have already been written.\r\n   */\r\n  async abort(): Promise<void> {\r\n    if (this.state.streamEnd) {\r\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\r\n      throw new MongoAPIError('Cannot abort a stream that has already completed');\r\n    }\r\n\r\n    if (this.state.aborted) {\r\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\r\n      throw new MongoAPIError('Cannot call abort() on a stream twice');\r\n    }\r\n\r\n    this.state.aborted = true;\r\n    await this.chunks.deleteMany({ files_id: this.id });\r\n  }\r\n\r\n  /**\r\n   * Tells the stream that no more data will be coming in. The stream will\r\n   * persist the remaining data to MongoDB, write the files document, and\r\n   * then emit a 'finish' event.\r\n   *\r\n   * @param chunk - Buffer to write\r\n   * @param encoding - Optional encoding for the buffer\r\n   * @param callback - Function to call when all files and chunks have been persisted to MongoDB\r\n   */\r\n  override end(): this;\r\n  override end(chunk: Buffer): this;\r\n  override end(callback: Callback<GridFSFile | void>): this;\r\n  override end(chunk: Buffer, callback: Callback<GridFSFile | void>): this;\r\n  override end(chunk: Buffer, encoding: BufferEncoding): this;\r\n  override end(\r\n    chunk: Buffer,\r\n    encoding: BufferEncoding | undefined,\r\n    callback: Callback<GridFSFile | void>\r\n  ): this;\r\n  override end(\r\n    chunkOrCallback?: Buffer | Callback<GridFSFile | void>,\r\n    encodingOrCallback?: BufferEncoding | Callback<GridFSFile | void>,\r\n    callback?: Callback<GridFSFile | void>\r\n  ): this {\r\n    const chunk = typeof chunkOrCallback === 'function' ? undefined : chunkOrCallback;\r\n    const encoding = typeof encodingOrCallback === 'function' ? undefined : encodingOrCallback;\r\n    callback =\r\n      typeof chunkOrCallback === 'function'\r\n        ? chunkOrCallback\r\n        : typeof encodingOrCallback === 'function'\r\n        ? encodingOrCallback\r\n        : callback;\r\n\r\n    if (this.state.streamEnd || checkAborted(this, callback)) return this;\r\n\r\n    this.state.streamEnd = true;\r\n\r\n    if (callback) {\r\n      this.once(GridFSBucketWriteStream.FINISH, (result: GridFSFile) => {\r\n        if (callback) callback(undefined, result);\r\n      });\r\n    }\r\n\r\n    if (!chunk) {\r\n      waitForIndexes(this, () => !!writeRemnant(this));\r\n      return this;\r\n    }\r\n\r\n    this.write(chunk, encoding, () => {\r\n      writeRemnant(this);\r\n    });\r\n\r\n    return this;\r\n  }\r\n}\r\n\r\nfunction __handleError(\r\n  stream: GridFSBucketWriteStream,\r\n  error: AnyError,\r\n  callback?: Callback\r\n): void {\r\n  if (stream.state.errored) {\r\n    return;\r\n  }\r\n  stream.state.errored = true;\r\n  if (callback) {\r\n    return callback(error);\r\n  }\r\n  stream.emit(GridFSBucketWriteStream.ERROR, error);\r\n}\r\n\r\nfunction createChunkDoc(filesId: ObjectId, n: number, data: Buffer): GridFSChunk {\r\n  return {\r\n    _id: new ObjectId(),\r\n    files_id: filesId,\r\n    n,\r\n    data\r\n  };\r\n}\r\n\r\nasync function checkChunksIndex(stream: GridFSBucketWriteStream): Promise<void> {\r\n  const index = { files_id: 1, n: 1 };\r\n\r\n  let indexes;\r\n  try {\r\n    indexes = await stream.chunks.listIndexes().toArray();\r\n  } catch (error) {\r\n    if (error instanceof MongoError && error.code === MONGODB_ERROR_CODES.NamespaceNotFound) {\r\n      indexes = [];\r\n    } else {\r\n      throw error;\r\n    }\r\n  }\r\n\r\n  const hasChunksIndex = !!indexes.find(index => {\r\n    const keys = Object.keys(index.key);\r\n    if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\r\n      return true;\r\n    }\r\n    return false;\r\n  });\r\n\r\n  if (!hasChunksIndex) {\r\n    await stream.chunks.createIndex(index, {\r\n      ...stream.writeConcern,\r\n      background: true,\r\n      unique: true\r\n    });\r\n  }\r\n}\r\n\r\nfunction checkDone(stream: GridFSBucketWriteStream, callback?: Callback): boolean {\r\n  if (stream.done) return true;\r\n  if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {\r\n    // Set done so we do not trigger duplicate createFilesDoc\r\n    stream.done = true;\r\n    // Create a new files doc\r\n    const filesDoc = createFilesDoc(\r\n      stream.id,\r\n      stream.length,\r\n      stream.chunkSizeBytes,\r\n      stream.filename,\r\n      stream.options.contentType,\r\n      stream.options.aliases,\r\n      stream.options.metadata\r\n    );\r\n\r\n    if (checkAborted(stream, callback)) {\r\n      return false;\r\n    }\r\n\r\n    stream.files.insertOne(filesDoc, { writeConcern: stream.writeConcern }).then(\r\n      () => {\r\n        stream.emit(GridFSBucketWriteStream.FINISH, filesDoc);\r\n        stream.emit(GridFSBucketWriteStream.CLOSE);\r\n      },\r\n      error => {\r\n        return __handleError(stream, error, callback);\r\n      }\r\n    );\r\n\r\n    return true;\r\n  }\r\n\r\n  return false;\r\n}\r\n\r\nasync function checkIndexes(stream: GridFSBucketWriteStream): Promise<void> {\r\n  const doc = await stream.files.findOne({}, { projection: { _id: 1 } });\r\n  if (doc != null) {\r\n    // If at least one document exists assume the collection has the required index\r\n    return;\r\n  }\r\n\r\n  const index = { filename: 1, uploadDate: 1 };\r\n\r\n  let indexes;\r\n  try {\r\n    indexes = await stream.files.listIndexes().toArray();\r\n  } catch (error) {\r\n    if (error instanceof MongoError && error.code === MONGODB_ERROR_CODES.NamespaceNotFound) {\r\n      indexes = [];\r\n    } else {\r\n      throw error;\r\n    }\r\n  }\r\n\r\n  const hasFileIndex = !!indexes.find(index => {\r\n    const keys = Object.keys(index.key);\r\n    if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\r\n      return true;\r\n    }\r\n    return false;\r\n  });\r\n\r\n  if (!hasFileIndex) {\r\n    await stream.files.createIndex(index, { background: false });\r\n  }\r\n\r\n  await checkChunksIndex(stream);\r\n}\r\n\r\nfunction createFilesDoc(\r\n  _id: ObjectId,\r\n  length: number,\r\n  chunkSize: number,\r\n  filename: string,\r\n  contentType?: string,\r\n  aliases?: string[],\r\n  metadata?: Document\r\n): GridFSFile {\r\n  const ret: GridFSFile = {\r\n    _id,\r\n    length,\r\n    chunkSize,\r\n    uploadDate: new Date(),\r\n    filename\r\n  };\r\n\r\n  if (contentType) {\r\n    ret.contentType = contentType;\r\n  }\r\n\r\n  if (aliases) {\r\n    ret.aliases = aliases;\r\n  }\r\n\r\n  if (metadata) {\r\n    ret.metadata = metadata;\r\n  }\r\n\r\n  return ret;\r\n}\r\n\r\nfunction doWrite(\r\n  stream: GridFSBucketWriteStream,\r\n  chunk: Buffer | string,\r\n  encoding?: BufferEncoding,\r\n  callback?: Callback<void>\r\n): boolean {\r\n  if (checkAborted(stream, callback)) {\r\n    return false;\r\n  }\r\n\r\n  const inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\r\n\r\n  stream.length += inputBuf.length;\r\n\r\n  // Input is small enough to fit in our buffer\r\n  if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {\r\n    inputBuf.copy(stream.bufToStore, stream.pos);\r\n    stream.pos += inputBuf.length;\r\n\r\n    callback && callback();\r\n\r\n    // Note that we reverse the typical semantics of write's return value\r\n    // to be compatible with node's `.pipe()` function.\r\n    // True means client can keep writing.\r\n    return true;\r\n  }\r\n\r\n  // Otherwise, buffer is too big for current chunk, so we need to flush\r\n  // to MongoDB.\r\n  let inputBufRemaining = inputBuf.length;\r\n  let spaceRemaining: number = stream.chunkSizeBytes - stream.pos;\r\n  let numToCopy = Math.min(spaceRemaining, inputBuf.length);\r\n  let outstandingRequests = 0;\r\n  while (inputBufRemaining > 0) {\r\n    const inputBufPos = inputBuf.length - inputBufRemaining;\r\n    inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);\r\n    stream.pos += numToCopy;\r\n    spaceRemaining -= numToCopy;\r\n    let doc: GridFSChunk;\r\n    if (spaceRemaining === 0) {\r\n      doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));\r\n      ++stream.state.outstandingRequests;\r\n      ++outstandingRequests;\r\n\r\n      if (checkAborted(stream, callback)) {\r\n        return false;\r\n      }\r\n\r\n      stream.chunks.insertOne(doc, { writeConcern: stream.writeConcern }).then(\r\n        () => {\r\n          --stream.state.outstandingRequests;\r\n          --outstandingRequests;\r\n\r\n          if (!outstandingRequests) {\r\n            stream.emit('drain', doc);\r\n            callback && callback();\r\n            checkDone(stream);\r\n          }\r\n        },\r\n        error => {\r\n          return __handleError(stream, error);\r\n        }\r\n      );\r\n\r\n      spaceRemaining = stream.chunkSizeBytes;\r\n      stream.pos = 0;\r\n      ++stream.n;\r\n    }\r\n    inputBufRemaining -= numToCopy;\r\n    numToCopy = Math.min(spaceRemaining, inputBufRemaining);\r\n  }\r\n\r\n  // Note that we reverse the typical semantics of write's return value\r\n  // to be compatible with node's `.pipe()` function.\r\n  // False means the client should wait for the 'drain' event.\r\n  return false;\r\n}\r\n\r\nfunction waitForIndexes(\r\n  stream: GridFSBucketWriteStream,\r\n  callback: (res: boolean) => boolean\r\n): boolean {\r\n  if (stream.bucket.s.checkedIndexes) {\r\n    return callback(false);\r\n  }\r\n\r\n  stream.bucket.once('index', () => {\r\n    callback(true);\r\n  });\r\n\r\n  return true;\r\n}\r\n\r\nfunction writeRemnant(stream: GridFSBucketWriteStream, callback?: Callback): boolean {\r\n  // Buffer is empty, so don't bother to insert\r\n  if (stream.pos === 0) {\r\n    return checkDone(stream, callback);\r\n  }\r\n\r\n  ++stream.state.outstandingRequests;\r\n\r\n  // Create a new buffer to make sure the buffer isn't bigger than it needs\r\n  // to be.\r\n  const remnant = Buffer.alloc(stream.pos);\r\n  stream.bufToStore.copy(remnant, 0, 0, stream.pos);\r\n  const doc = createChunkDoc(stream.id, stream.n, remnant);\r\n\r\n  // If the stream was aborted, do not write remnant\r\n  if (checkAborted(stream, callback)) {\r\n    return false;\r\n  }\r\n\r\n  stream.chunks.insertOne(doc, { writeConcern: stream.writeConcern }).then(\r\n    () => {\r\n      --stream.state.outstandingRequests;\r\n      checkDone(stream);\r\n    },\r\n    error => {\r\n      return __handleError(stream, error);\r\n    }\r\n  );\r\n  return true;\r\n}\r\n\r\nfunction checkAborted(stream: GridFSBucketWriteStream, callback?: Callback<void>): boolean {\r\n  if (stream.state.aborted) {\r\n    if (typeof callback === 'function') {\r\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosedError\r\n      callback(new MongoAPIError('Stream has been aborted'));\r\n    }\r\n    return true;\r\n  }\r\n  return false;\r\n}\r\n"]},"metadata":{},"sourceType":"script","externalDependencies":[]}